{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset used here is NIPS Papers dataset from Kaggle.\n",
    "Only the id, year, title || ' ' || abstract as abstract have been used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Algorithms for Non-negative Matrix Factorizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Competition Adds Complexity It is known that d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                           abstract\n",
       "0  1861  2000  Algorithms for Non-negative Matrix Factorizati...\n",
       "1  1975  2001  Characterizing Neural Gain Control using Spike...\n",
       "2  3163  2007  Competition Adds Complexity It is known that d...\n",
       "3  3164  2007  Efficient Principled Learning of Thin Junction...\n",
       "4  3167  2007  Regularized Boost for Semi-Supervised Learning..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "dataset = pandas.read_csv('../nips-papers/papers_modified.csv', delimiter=',')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Algorithms for Non-negative Matrix Factorizati...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Competition Adds Complexity It is known that d...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning...</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                           abstract  word_count\n",
       "0  1861  2000  Algorithms for Non-negative Matrix Factorizati...         112\n",
       "1  1975  2001  Characterizing Neural Gain Control using Spike...          88\n",
       "2  3163  2007  Competition Adds Complexity It is known that d...          70\n",
       "3  3164  2007  Efficient Principled Learning of Thin Junction...         150\n",
       "4  3167  2007  Regularized Boost for Semi-Supervised Learning...         124"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wordcount of each abstract\n",
    "dataset['word_count'] = dataset['abstract'].apply(lambda x: len(str(x).split(\" \")))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3924.000000\n",
       "mean      155.888124\n",
       "std        46.001025\n",
       "min        27.000000\n",
       "25%       122.000000\n",
       "50%       151.000000\n",
       "75%       185.000000\n",
       "max       325.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics related to word count\n",
    "dataset.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the         30107\n",
       "of          21685\n",
       "a           16518\n",
       "and         14218\n",
       "to          13104\n",
       "in           9454\n",
       "for          8382\n",
       "that         7841\n",
       "is           7687\n",
       "We           6239\n",
       "on           5704\n",
       "we           5167\n",
       "with         5142\n",
       "as           3686\n",
       "this         3677\n",
       "are          3546\n",
       "an           3398\n",
       "by           3302\n",
       "can          2958\n",
       "learning     2903\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common words\n",
    "freq = pandas.Series(' '.join(dataset['abstract']).split()).value_counts()[:20]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aggregate           1\n",
       "detector.           1\n",
       "chains.             1\n",
       "(Robins,            1\n",
       "(LV-RNN)            1\n",
       "(legislation)       1\n",
       "(binary             1\n",
       "Inventories         1\n",
       "Nowcasting          1\n",
       "free-form.          1\n",
       "smoothers,          1\n",
       "linkages,           1\n",
       "Topic-Based         1\n",
       "inference).         1\n",
       "Comparison-based    1\n",
       "Cuboid              1\n",
       "mirrored            1\n",
       "coordinate.         1\n",
       "M-statistics        1\n",
       "injections          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncommon words\n",
    "freq1 = pandas.Series(' '.join(dataset['abstract']).split()).value_counts()[-20:]\n",
    "freq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# List of stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\"]\n",
    "stop_words = stop_words.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "# Cleaning dataset\n",
    "n = len(dataset['abstract'])\n",
    "for i in range(0, n):\n",
    "    # Remove punctuations\n",
    "    text = re.sub('[^a-zA-Z]', ' ', dataset['abstract'][i])\n",
    "    \n",
    "    # Convert everything to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove tags\n",
    "    text = re.sub('&lt;/?.*>&gt;', ' &lt;&gt; ', text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text = re.sub('(\\\\d|\\\\W)+', ' ', text)\n",
    "    \n",
    "    # Convert string to list\n",
    "    text = text.split()\n",
    "    \n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    # Lemmatization\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = [lem.lemmatize(word) for word in text if not word in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
